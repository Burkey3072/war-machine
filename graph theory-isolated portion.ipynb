{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9910da1e-b39d-474d-acde-85b58ed4308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "rng = np.random.default_rng()\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117093d1-fe05-40ee-aeae-87f176181cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Inter_StateWarData = pd.read_csv(\"Inter-StateWarData_v4.0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c599fc04-6c18-4f8e-8594-aaaeea746c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import alliances data\n",
    "df_raw= pd.read_csv(\"alliance_v4.1_by_directed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7380d4fa-d74d-4455-ad7e-b0453960b922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ccode1', 'state_name1', 'ccode2', 'state_name2', 'defense',\n",
       "       'neutrality', 'entente', 'datecode_st', 'datecode_end'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove shit we don't care about\n",
    "dfpp=df_raw.drop(labels=list(['version4id','left_censor','right_censor','nonaggression','version']),axis=1)\n",
    "#filter out aliances where we don't know the end or start day's\n",
    "#solution to use notna from stack overflow\n",
    "df_clean1 = dfpp[dfpp['dyad_st_day'].notna()]\n",
    "df=df_clean1[df_clean1['dyad_end_day'].notna()]\n",
    "#convert to a date code\n",
    "def datecode(year,month,day):\n",
    "    datecode=year*365.25+month*30+day\n",
    "    return datecode\n",
    "\n",
    "starts=[]\n",
    "ends=[]\n",
    "#nessacary for iteration below\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "for i in range(0,len(df)):\n",
    "    #filter out non-defense non-entente alliances\n",
    "    if not (df['defense'][i]==1.0) or (df['entente'][i] ==1) or (df['neutrality'][i]==1):\n",
    "        #print('')\n",
    "        df.drop(i,axis=0,inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "#convert to datecodes\n",
    "for i in range(0,len(df)):\n",
    "    dcs=datecode(df['dyad_st_year'][i],df['dyad_st_month'][i],df['dyad_st_day'][i])\n",
    "    starts.append(dcs)\n",
    "    dce=datecode(df['dyad_end_year'][i],df['dyad_end_month'][i],df['dyad_end_day'][i])\n",
    "    ends.append(dce)\n",
    "df['datecode_st']=starts\n",
    "df['datecode_end']=ends\n",
    "#now that we have datecodes, drop the year,month,day labels\n",
    "df.drop(axis=1,labels=['dyad_end_year','dyad_end_month','dyad_end_day','dyad_st_year','dyad_st_month','dyad_st_day'], inplace=True)\n",
    "#we now have cleanish data\n",
    "alliances=df\n",
    "alliances.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ae3b74-1ca0-4ecf-be02-77e581a86664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove shit we don't care about\n",
    "war_droped=Inter_StateWarData.drop(labels=list(['Version','StartMonth2', 'StartDay2','StartYear2']),axis=1)\n",
    "#filter out aliances where we don't know the end or start day's\n",
    "#solution to use notna from stack overflow\n",
    "isw_data_w_s_dates = war_droped[war_droped['StartDay1'].notna()]\n",
    "isw_data_w_e_dates = isw_data_w_s_dates[isw_data_w_s_dates['EndDay2'].notna()]\n",
    "isw_partial  = isw_data_w_e_dates\n",
    "starts=[]\n",
    "ends=[]\n",
    "#nessacary for iteration below\n",
    "isw_partial.reset_index(drop=True,inplace=True)\n",
    "#convert to datecodes\n",
    "for i in range(0,len(isw_partial)):\n",
    "    dcs=datecode(isw_partial['StartYear1'][i],isw_partial['StartMonth1'][i],isw_partial['StartDay1'][i])\n",
    "    starts.append(dcs)\n",
    "    if isw_partial['EndDay2'][i]<0:  #means we don't have a battle inturruption\n",
    "        dce=datecode(isw_partial['EndYear1'][i],isw_partial['EndMonth1'][i],isw_partial['EndDay1'][i])\n",
    "    else:\n",
    "        dce=datecode(isw_partial['EndYear2'][i],isw_partial['EndMonth2'][i],isw_partial['EndDay2'][i])\n",
    "    ends.append(dce)\n",
    "isw_partial['datecode_st']=starts\n",
    "isw_partial['datecode_end']=ends\n",
    "#now that we have datecodes, drop the year,month,day labels\n",
    "isw_partial.drop(axis=1,labels=['StartMonth1', 'StartDay1', 'StartYear1','EndMonth2','EndDay2', 'EndYear2','EndMonth1', 'EndDay1','EndYear1'], inplace=True)\n",
    "#we now have cleanish data\n",
    "isw_data=isw_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43399251-4aa7-4bb0-b334-7ab08b898827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a graph of our allliances, for a given point in time by first filtering for those aliances wich ended before our start time,\n",
    "# and then those with started after our end time\n",
    "# we consider defense pacts and entente's as alliances, and ignore all other forms alliance forms, presuming enemies.\n",
    "\n",
    "#now we should have a graph of alliances for some date code \n",
    "#graph this to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca221e1-041c-46fc-9340-ce64b385404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for a given datecode, we construct a graph with all alliances active at that time:\n",
    "#first we filter for only alliances that are within our datecode\n",
    "def date_filter(dataframe,datecode):\n",
    "    df=dataframe.reset_index(drop=True,inplace=False)\n",
    "    for i in range(0,len(df)):\n",
    "    #filter out alliances that aren't active, ie not dc_st < datecode< dcend\n",
    "        if not (df['datecode_st'][i]<= datecode<=df['datecode_end'][i]):\n",
    "            df.drop(i,axis=0,inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    return df\n",
    "#then we use the alliances to construct a graph (with only the alliances that we know)\n",
    "def graph_constructor(dataframe,datecode):\n",
    "    df=date_filter(dataframe=dataframe,datecode=datecode)\n",
    "    edges_df = df.drop(labels=['state_name1','state_name2','defense','entente','datecode_end','datecode_st'],axis=1)\n",
    "    #this feels stupid, but is probably the easiest way to do this\n",
    "    edges=[]\n",
    "    for i in range(0,len(edges_df)):#we use country codes for our verticies, to save memory, \n",
    "        #and append the start and end date of each alliance as a attributte of it\n",
    "        edge=(df['ccode1'][i],df['ccode2'][i],{'start':df['datecode_st'][i],'end':df['datecode_end'][i]})\n",
    "        edges.append(edge)\n",
    "    alliances=nx.Graph(edges)\n",
    "    return alliances\n",
    "\n",
    "G= graph_constructor(df,665325.0)\n",
    "#we can look up names later using the function defined below\n",
    "def find_country_name(country_id, dataframe):\n",
    "    name = df.where(df['ccode1']==country_id)['state_name1'].dropna().reset_index(drop=True)[0]\n",
    "    return name\n",
    "def append_state_names(graph,df):\n",
    "    labels={}\n",
    "    for node in graph.nodes:\n",
    "        name=find_country_name(node,df)\n",
    "        graph.nodes[node]['name']=name\n",
    "        labels[node]=name\n",
    "    return graph,labels\n",
    "#G,labels=append_state_names(G,df)\n",
    "#nx.draw_kamada_kawai(G,with_labels=True)\n",
    "def draw_graph(graph,df):\n",
    "    graph,names=append_state_names(graph,df)\n",
    "    nx.draw_kamada_kawai(graph,labels=names)\n",
    "    plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "619ceabb-3d7e-4ac0-bd6c-71d28425abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#animation for time codes\n",
    "start=665325.0\n",
    "stop=698067.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e1e6ff-1144-4b90-88fe-a450b6e68e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usefull functions\n",
    "#use the function below to map the probabilities of being in a class to the class itself, with a harsh cut-off of 0.5\n",
    "def binarize(prob):#from hw 03\n",
    "    if prob<0.5:\n",
    "        return 0\n",
    "    elif prob==0.5:\n",
    "        #rand =  rng.integers(low=0,high=8)%2\n",
    "        #rand=1 #use this to favor alliance stability\n",
    "        rand=0 # favor instability\n",
    "        return rand\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "614cfecb-a4f2-4db6-8104-a21c7a581c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can perform stability analysis, we/I (kyle) use the following metrics:\n",
    "# for each neighbor (ally):\n",
    "#how many of our neighbors (so the neighbors of neighbors) are enemies with each other (the original neigbors), and how many are allies, how many allies do we have\n",
    "#ie each vertex(country) has a repulsive force for allying with another country (the numbere of it's current allies that are enemies with said country)\n",
    "#and a attractive force (number of allies already allied with said country)\n",
    "#we define functions for returning said forces below\n",
    "\n",
    "def forces(graph, source_vertex, attracting_vertex):\n",
    "    allies = graph.neighbors(source_vertex)\n",
    "    attraction=0\n",
    "    repulsion=0\n",
    "    for ally in allies:\n",
    "        if attracting_vertex in graph.neighbors(ally):\n",
    "            attraction+=1\n",
    "        else:\n",
    "            repulsion+=1\n",
    "    return attraction, repulsion\n",
    "\n",
    "#recusive version of above for our k-neighbor's\n",
    "def k_forces(graph,source_verticies,sink_vertex,k=1):\n",
    "    allies = graph.neighbors(source_verticies)\n",
    "    if k<=0:\n",
    "        for ally in allies:\n",
    "            if sink_vertex in graph.neighbors(ally):\n",
    "                k_attraction+=1\n",
    "            else:\n",
    "                k_repulsion+=1\n",
    "        return k_attraction,k_repulsion,len(allies)\n",
    "    else:\n",
    "        k-=1\n",
    "        k_forces(graph,allies,sink_vertex,k)\n",
    "#clique analysis:\n",
    "#WARNING THIS IS NP-COMPLETE AND THEREFORE SLOWS WITH SCALE EXTREMELY FAST\n",
    "#have we formed a stable clique?, does is the graph either 2 complete subgraphs or a complete graph?\n",
    "\n",
    "#we don't use clique analysis here yet, could be fed into ml algorithm but would be very slow\n",
    "#def k_cliques(graph):\n",
    "\n",
    "def is_complete_graph(G): #from google ai response/overview (nov  18 2024,16:03) to \"networkx check if graph is complete\"\n",
    "    \"\"\"\n",
    "    Checks if a given graph is complete.\n",
    "\n",
    "    Args:\n",
    "        G (networkx.Graph): The graph to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the graph is complete, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    n = G.number_of_nodes()\n",
    "    edges=G.number_of_edges()\n",
    "    return edges == n * (n - 1) // 2 \n",
    "    #formula for number of edges of a complete graph, we can use since \n",
    "    #networkx doesn't allow duuplicate edges in a default graph, and edges in a complete graph is n*(n-1)//2 \n",
    "\n",
    "def component_analysis(graph,strict=False):\n",
    "    \"\"\"\n",
    "    Input's: graph\n",
    "    we find all components of the graph, check if they are complete,\n",
    "    since by a mathematical theorem we know that the only stable arrangements are \n",
    "    2 distinct complete graphs, or 1 complete graph\n",
    "    we check for the above scenarios, and output if the graph is stable (to continue our simulation)\n",
    "    or unstable. We also output which case it is in, if stable.\n",
    "    we also output the number of components and complete components for potential use elsewhere \n",
    "    and a war \"probability\" which is essentially a binary yes no of whether or not we are made of only complete components\n",
    "    this could of course be modified to be much more complex, but we keep it simple for now\n",
    "    outputs: number_connected_components, number_of_complete_components, stable, war,two_distinct_sg\n",
    "    \"\"\"\n",
    "    if type(graph)==type(None):\n",
    "        return 1,1,False,0,False\n",
    "    components = nx.connected_components(graph)\n",
    "    number_connected_components=nx.number_connected_components(graph)\n",
    "    number_of_complete_components=0\n",
    "    complete_com_sizes=[]\n",
    "    stable=False\n",
    "    war=0\n",
    "    if number_connected_components==0:\n",
    "        return 0,0,False,False,False\n",
    "    two_distinct_sg=False\n",
    "    components_subgraph_list = [graph.subgraph(c).copy() for c in components] # modified from networkx documentation[https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.components.connected_components.html], converts our list of component generators into a list of component subgraphs  \n",
    "    for subgraph in components_subgraph_list:\n",
    "        if is_complete_graph(subgraph):\n",
    "            number_of_complete_components+=1\n",
    "            complete_com_sizes.append(len(subgraph.nodes()))\n",
    "        else:\n",
    "            continue\n",
    "    if number_connected_components==number_of_complete_components:\n",
    "        if number_of_complete_components==1:\n",
    "            #print(f'everyone is friends, peace is likely to persist for a while')\n",
    "            stable=True\n",
    "            war=0\n",
    "        elif number_of_complete_components==2:\n",
    "            stable=True\n",
    "            two_distinct_sg=True\n",
    "            war=1\n",
    "            #print(f'war is inevitable, we have a stable graph, with 2 complete components of sizes {complete_com_sizes[0]}, and {complete_com_sizes[1]} ')\n",
    "        else:\n",
    "            stable=False\n",
    "            #war=False\n",
    "            war=1-(1/(number_connected_components))#? clearly war is likely, but it probably isn't inevitable\n",
    "            #print(f'graph is unstable, with  {number_connected_components} seperate alliance gropus, war is probably inevitable')\n",
    "    else:\n",
    "        stable=False\n",
    "        if (not strict) and number_connected_components>1:\n",
    "            war=1.0\n",
    "            stable=False\n",
    "        #print(f'graph is unstable, with {number_connected_components} groups, allilances are likely to shift before war can break out')\n",
    "    return number_connected_components,number_of_complete_components,stable,war,two_distinct_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6eaba65a-07db-4522-8b21-957c3e190b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_favor(graph,time,source_country,sink_country):\n",
    "    \"\"\"\n",
    "    Inputs: graph, timecode, source and sink countries to check\n",
    "    ouputs: stability of edge: 1.0 strongly favors alliance, -1.0 strongly favors enemies\n",
    "    \"\"\"\n",
    "    attr=0\n",
    "    repul=0\n",
    "    attr,repul= forces(graph,source_vertex=source_country,attracting_vertex=sink_country)\n",
    "    tsize=attr+repul\n",
    "    net_force= (attr-repul) -1 #favor alliance degredation slightly\n",
    "    #if -1<=net_force<=0:#favor alliance formation slightly\n",
    "    #    net_force += 1\n",
    "    if tsize==0:\n",
    "        return 0\n",
    "    scaled_force  =  (attr-repul)/tsize\n",
    "    if net_force==0:#favor alliance degradation slightly\n",
    "        scaled_force-=1/tsize\n",
    "    #normalized_force =  scaled_force*.5 +.5#need to correct currently returns stability of graph edge, not likelyhood of f>\n",
    "    return scaled_force\n",
    "\n",
    "def force_flip(graph,time,source_country,sink_country,pred_params):\n",
    "    \"\"\"\n",
    "    Inputs: graph, timecode, source and sink countries to check\n",
    "    ouputs: flip probability, 1.0 is high flip chance, 0.0 is no flip chance\n",
    "    \"\"\"\n",
    "    scaled_force=force_favor(graph,time,source_country,sink_country)\n",
    "    normalized_force =  scaled_force*.5 +.5\n",
    "    if graph.has_edge(source_country,sink_country):\n",
    "        if scaled_force>0:#alliance favored and we already have one, low flip likelyhood\n",
    "            return 1-normalized_force #normalized force is >0.5 in this case,  so low flip likelyhood is 1-normalized force\n",
    "        elif  scaled_force<0:#no alliance/enemies favored, but we are currently allies,  high flip likelyhood\n",
    "            return 1- normalized_force#normalized force is <0.5 in this case,  so high flip likelyhood is 1-normalized force\n",
    "        else: #no side favored, assume random chance of flipping (note this is wrong, we should probably default to a low l>\n",
    "            return 0.5\n",
    "    else: # we don't already have an edge, meaning we are enemies between source and sink\n",
    "        if scaled_force>0: #alliance formation favored\n",
    "            return normalized_force\n",
    "        elif  scaled_force<0: #favor staying as enemies\n",
    "            return normalized_force\n",
    "        else: #neither side favored\n",
    "            return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2537ddb2-6f80-4653-bbd4-894ca3c0e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be done by other group members:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "finish these cells\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#\n",
    "def train_models():\n",
    "    #seperate call to train any models passed in pred_params to likelyhood of relationship flipping function\n",
    "    return models\n",
    "\n",
    "def  generate_flip_dataset(start_tc,end_tc):\n",
    "    #takes in a set of times, and returns a timecode of when edges flipped for training\n",
    "    \n",
    "    return data\n",
    "\n",
    "def likelyhood_of_relationship_flipping(graph,time,source_country,sink_country,pred_params):\n",
    "    \"\"\" \n",
    "    Input: graph, timecode, the source and sink countries \n",
    "    (order doesn't/shouldn't actually matter) and any aditional prediction parameters we need\n",
    "    Output: a 0-1 probability that the relationshib between 2 countries will flip\n",
    "    how/methods: logistic regression? PCA? \"\"\"\n",
    "    return flip_probablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07585e42-6267-43fb-b850-194712f6a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_edges(edge_list):\n",
    "    #G=nx.Graph()\n",
    "    # for edge in edge_list:\n",
    "    #    G.add_edge(edge[0],edge[1])\n",
    "    edge_graph = nx.Graph(edge_list)\n",
    "    edges=[e for e in edge_graph.edges]\n",
    "    #print(edges)\n",
    "    return edges \n",
    "    \n",
    "def flipped_at_list_graph(G,flip_relations_list):\n",
    "    #flips the realations of a graph at the listed \"edges\"\n",
    "    #first we deduplicate identical edges\n",
    "    graph=G.copy()\n",
    "    frl_clean=dedupe_edges(flip_relations_list)\n",
    "    #now we can flip\n",
    "    for i in range(0,len(frl_clean)):\n",
    "        edge=frl_clean[i]\n",
    "        u=edge[0]\n",
    "        v=edge[1]\n",
    "        if graph.has_edge(u,v):\n",
    "            graph.remove_edge(u,v)\n",
    "        else:\n",
    "            graph.add_edge(u,v)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4503806e-f09b-43f0-ae99-aad4b1423d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we predict alliance changes for each vertex at each timestep:\n",
    "\n",
    "def Simulate_at_graph(graph, time, pred_params):\n",
    "    flip_relations_list=[]\n",
    "    #number_connected_components,number_of_complete_components,stable,war,two_distinct_sg = component_analysis(graph)# check if war is inevitable yet\n",
    "    #check each possible edge \n",
    "    #SLOW\n",
    "    for source_country in graph.nodes():\n",
    "        #graph_no_source=graph.copy().remove_node(source_country)\n",
    "        #just loop twice, ignoring self connections\n",
    "        for sink_country in graph.nodes():\n",
    "            if sink_country==source_country:\n",
    "                continue\n",
    "            else:\n",
    "                if not type(graph) == type(None):#means we have more than 1 node in our graph\n",
    "                    #check if we are likely to change relations\n",
    "                    flip_chance = force_flip(graph,time,source_country,sink_country,pred_params)\n",
    "                    #print(source_country,sink_country,flip_chance)\n",
    "                    flip_chance=binarize(flip_chance)\n",
    "                    if flip_chance == 1.0:\n",
    "                        flip_relations_list.append((source_country,sink_country))\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "    # now create a new graph with our flipped relations, and return it\n",
    "    return flipped_at_list_graph(graph,flip_relations_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31f25263-ca7b-43a1-9b5c-76b9dca3cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_from_to(graph,start_time,end_time,time_steps=7,pred_params=None,alliances=None):\n",
    "    \"\"\"\n",
    "    Inputs: graph, start_time (days AD), end_time (days AD), time_steps (in days), prediction parameters\n",
    "    Outputs: predicted war date, and either graph animation in notebook, or saved mp4, \n",
    "    with prediction labels\n",
    "    \n",
    "    this function is our simulation harness, we:\n",
    "    first:\n",
    "    check if we are in a stable state, and stop if we are\n",
    "    check for war inevitability in the above step\n",
    "    output results if we are stable, which should occur anyways\n",
    "    then:\n",
    "    run our simulation on our current graph, \n",
    "    commit the proposed changes,\n",
    "    and advance to the next timestep, until we either:\n",
    "    reach stability, in which case we output if war is likely, \n",
    "    we could skip ahead (in the real data) to when we are unstable, but we don't as of yet, \n",
    "    that is for a seperate function.\n",
    "    or reach our end time of the simulation\n",
    "    \"\"\"\n",
    "    G=graph\n",
    "    graphs_over_time=[]\n",
    "    war=0.0\n",
    "    stable=False\n",
    "    times=np.arange(start=start_time,stop=end_time,step=time_steps)\n",
    "    for time in times:\n",
    "        number_connected_components,number_of_complete_components,stable,war,two_distinct_sg = component_analysis(G)# check if war is inevitable yet\n",
    "        #draw_graph(G,alliances)\n",
    "        #clear_output(wait=True)\n",
    "        if stable:\n",
    "            graphs_over_time.append(G)\n",
    "            if two_distinct_sg:\n",
    "                war=1.0\n",
    "                nx.draw(G)\n",
    "                return graphs_over_time,time,war,stable #time of predicted war inevitability\n",
    "            else:\n",
    "                return graphs_over_time,time,war,stable\n",
    "        else:\n",
    "            graphs_over_time.append(G)\n",
    "            G=Simulate_at_graph(G,time,pred_params)\n",
    "    return graphs_over_time,end_time,war,stable\n",
    "\n",
    "\n",
    "def war_predictions(base_alliance_dataframe,starting_graph,start_time,end_time,time_steps=7,pred_params=None):\n",
    "    \"\"\"\n",
    "    simulates graph, same as above\n",
    "    fast forwards to when we aren't stable to get more war predictions if we are\n",
    "    stores predicted times of war in a list, that get's returned\n",
    "    \"\"\"\n",
    "    war_times = []\n",
    "    graph_blocks=[]\n",
    "    #we tile simulations together when they end\n",
    "    #how to do this\n",
    "    current_last_time=start_time\n",
    "    prev_last_time=0\n",
    "    graph=starting_graph\n",
    "\n",
    "    #until we reach the end of our simulation time, keep runing\n",
    "    while current_last_time <= end_time:\n",
    "        #run the simulation until we either end or hit a block\n",
    "        graphs_over_time_block, current_last_time, war, stable = simulate_from_to(graph,current_last_time,end_time,time_steps,pred_params,alliances=base_alliance_dataframe)\n",
    "        #skip to next step if we get stuck\n",
    "        war=binarize(war)\n",
    "        if prev_last_time == current_last_time:\n",
    "            print(\"stuck at:  \",current_last_time, \" resetting to truth at 1 timestep\")\n",
    "            current_last_time+= time_steps\n",
    "            #reset starting graph from dataframe, to known real alliances\n",
    "            graph=graph_constructor(base_alliance_dataframe,current_last_time)\n",
    "            \n",
    "        if not len(graphs_over_time_block)==0: # only append to simulation chain if we actually did something\n",
    "            graph_blocks.append(graphs_over_time_block)\n",
    "        \n",
    "        prev_last_time=current_last_time\n",
    "        \n",
    "        if war==1.0:\n",
    "            wg=graph_blocks[-1][-1]#.nodes()# most recent graph block, most recent graph (the one where war is probable)\n",
    "            #wg=graphs_over_time_block[-1]# most recent graph (the one where war is probable)\n",
    "            states=wg.nodes()\n",
    "            war_times.append((current_last_time,states))\n",
    "            print(\"war at:  \",current_last_time, \"resetting to data\")\n",
    "            #draw war graph as a sanity check\n",
    "            draw_graph(wg,base_alliance_dataframe)\n",
    "            #resetting starting graph from dataframe, to known real alliances\n",
    "            graph=graph_constructor(base_alliance_dataframe,current_last_time)\n",
    "        if stable:\n",
    "           # print(\"predicted stable at:  \",current_last_time)\n",
    "            if not war:\n",
    "            #    print(\"reseting to truth\")\n",
    "                graph=graph_constructor(base_alliance_dataframe,current_last_time)\n",
    "    print(\"ending at\", current_last_time)\n",
    "    return war_times,graph_blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b09de5-860e-4ed2-a69b-7866892ed5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_check_from_to(graph,start_time,end_time,time_steps=30,pred_params=None,alliances=None):\n",
    "    \"\"\"\n",
    "    Inputs: graph, start_time (days AD), end_time (days AD), time_steps (in days), prediction parameters\n",
    "    Outputs: predicted war date, and either graph animation in notebook, or saved mp4, \n",
    "    with prediction labels\n",
    "    \n",
    "    this function is our simulation harness, we:\n",
    "    first:\n",
    "    check if we are in a stable state, and stop if we are\n",
    "    check for war inevitability in the above step\n",
    "    output results if we are stable, which should occur anyways\n",
    "    then:\n",
    "    we update our graph to the next time, and check again until\n",
    "    we reach our end time of the simulation\n",
    "    \"\"\"\n",
    "    graph=graph_constructor(alliances,start_time)\n",
    "    G=graph\n",
    "    stable=False\n",
    "    wartimes=[]\n",
    "    graphs=[]\n",
    "    times=np.arange(start=start_time,stop=end_time,step=time_steps)\n",
    "    for time in times:\n",
    "        number_connected_components,number_of_complete_components,stable,war,two_distinct_sg = component_analysis(G)# check if war is inevitable yet\n",
    "        if war>0.5:\n",
    "            #we predict war\n",
    "            wartimes.append((time,G.nodes()))\n",
    "        G=graph_constructor(alliances,time)\n",
    "    return wartimes,graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc4d072-37fd-427f-9249-41e0e06c73b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_check_strict(graph,start_time,end_time,time_steps=30,pred_params=None,alliances=None):\n",
    "    \"\"\"\n",
    "    Inputs: graph, start_time (days AD), end_time (days AD), time_steps (in days), prediction parameters\n",
    "    Outputs: predicted war date, and either graph animation in notebook, or saved mp4, \n",
    "    with prediction labels\n",
    "    \n",
    "    this function is our simulation harness, we:\n",
    "    first:\n",
    "    check if we are in a stable state, and stop if we are\n",
    "    check for war inevitability in the above step\n",
    "    output results if we are stable, which should occur anyways\n",
    "    then:\n",
    "    we update our graph to the next time, and check again until\n",
    "    we reach our end time of the simulation\n",
    "    \"\"\"\n",
    "    graph=graph_constructor(alliances,start_time)\n",
    "    G=graph\n",
    "    stable=False\n",
    "    wartimes=[]\n",
    "    graphs=[]\n",
    "    times=np.arange(start=start_time,stop=end_time,step=time_steps)\n",
    "    for time in times:\n",
    "        number_connected_components,number_of_complete_components,stable,war,two_distinct_sg = component_analysis(G)# check if war is inevitable yet\n",
    "        if war>0.5:\n",
    "            #we predict war\n",
    "            wartimes.append((time,G.nodes()))\n",
    "        G=graph_constructor(alliances,time)\n",
    "    return wartimes,graphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d9ef788-d9b8-4118-82bb-0324e0aeb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measuring accuracy\n",
    "\n",
    "def gen_war_dataset_for_timecodes(df,start_dc,stop_dc):\n",
    "    data=df.reset_index(drop=True,inplace=False)\n",
    "    for i in range(0,len(data)):\n",
    "    #filter out war's that aren't active within our timerange,\n",
    "    #ie war_end_date <start or  war_start_date > stop\n",
    "        if (data['datecode_st'][i]>stop_dc) or (data['datecode_end'][i]<start_dc):\n",
    "            data.drop(i,axis=0,inplace=True)\n",
    "    data.reset_index(drop=True,inplace=True)\n",
    "    return data\n",
    "\n",
    "def find_matching_war(countries, date, war_data_frame,window=30*6):\n",
    "    \"\"\"\n",
    "    Input: country code id's as a iterable list of nodes; countries\n",
    "    date: earliest datecode of war,\n",
    "    window: size in day's of window to search through\n",
    "    war_datwar_data_frame: dataframe with start and stop datecodes for actual war's, and\n",
    "    \"\"\"\n",
    "    search_data_frame=gen_war_dataset_for_timecodes(war_data_frame,start_dc=date, stop_dc=date+window)\n",
    "    for i in range(0,len(search_data_frame)): #loop over all the real war's that occured for our search time period\n",
    "        for country in countries: #loop over our predicted countries at war\n",
    "            if search_data_frame['ccode'][i]==country: #if any of them are at war, which matches the actual dataframe country code war,\n",
    "                #assume we have found our war\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def true_pred_accuracy(war_pred,true_war_df,start_time,end_time,day_window=30*6,): #six month window by default, based off ww1 outbreak time\n",
    "    #when we predict a war, how often does one actually break out between our component alliances within a given time window\n",
    "    correct_num_predictions=0\n",
    "    false_num_predictions=0\n",
    "    if not len(war_pred)==0:\n",
    "        for predicted_war in war_pred:\n",
    "            war_earliest_date=predicted_war[0]\n",
    "            countries=predicted_war[1]\n",
    "            matching_war_found=find_matching_war(countries,war_earliest_date,true_war_df,window=day_window)\n",
    "            if matching_war_found:\n",
    "                correct_num_predictions+=1\n",
    "            else:\n",
    "                false_num_predictions+=1\n",
    "    total_pred=(correct_num_predictions+false_num_predictions)\n",
    "    if total_pred==0:\n",
    "        if len(gen_war_dataset_for_timecodes(true_war_df,start_dc=start_time,stop_dc=end_time))==0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    else:\n",
    "        positive_accuracy= correct_num_predictions/total_pred\n",
    "        return positive_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baea1287-64b8-4e28-80b9-2cfa29e76c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=665325.0\n",
    "end_time=679067.75\n",
    "alliances=df\n",
    "real_wars=isw_data\n",
    "#print(pred_raw_war_times[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87590423-fd04-48d1-89ad-182007bcf782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "#procedural run our model time:\n",
    "start_time=665325.0\n",
    "end_time=679067.75\n",
    "alliances=df\n",
    "real_wars=isw_data\n",
    "G= graph_constructor(df,start_time)\n",
    "#draw_graph(G,alliances)\n",
    "#graph metric\n",
    "pred_raw_war_times= raw_check_from_to(G,start_time=start_time,end_time=end_time,time_steps=30,pred_params=None,alliances=alliances)\n",
    "pred_rew_war_strict=\n",
    "#pred_war_times_s, graphs_over_time = war_predictions(base_alliance_dataframe=alliances,starting_graph=G,start_time=start_time,end_time=end_time,time_steps=7,pred_params=None)\n",
    "\n",
    "#positive_rate_s=(true_pred_accuracy(pred_war_times,real_wars,start_time=start_time,end_time=end_time,day_window=30*12,))\n",
    "positive_rate_r=true_pred_accuracy(pred_raw_war_times[0],real_wars,start_time=start_time,end_time=end_time,day_window=30*12)\n",
    "#print(pred_raw_war_times)\n",
    "#print(component_analysis(graphs_over_time[-1][-1]))\n",
    "#draw_graph(graph_constructor(alliances,pred_war_times[0][0]),alliances)\n",
    "print(positive_rate_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f578e51-e078-4c7f-8097-cffd8d19a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_dataset(base_dataframe=dfpp, conditions=[]):\n",
    "    dfpp=base_dataframe\n",
    "    df_clean1 = dfpp[dfpp['dyad_st_day'].notna()]\n",
    "    df=df_clean1[df_clean1['dyad_end_day'].notna()]\n",
    "    #convert to a date code\n",
    "    def datecode(year,month,day):\n",
    "        datecode=year*365.25+month*30+day\n",
    "        return datecode\n",
    "    \n",
    "    starts=[]\n",
    "    ends=[]\n",
    "    #nessacary for iteration below\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    for i in range(0,len(df)):\n",
    "        #filter out non-condition\n",
    "        conditions_satisfied=False\n",
    "        for index in conditions:\n",
    "            if df[index][i]==1:\n",
    "                conditions_satisfied=True\n",
    "        if not (conditions_satisfied):\n",
    "            #print('')\n",
    "            df.drop(i,axis=0,inplace=True)\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    #convert to datecodes\n",
    "    for i in range(0,len(df)):\n",
    "        dcs=datecode(df['dyad_st_year'][i],df['dyad_st_month'][i],df['dyad_st_day'][i])\n",
    "        starts.append(dcs)\n",
    "        dce=datecode(df['dyad_end_year'][i],df['dyad_end_month'][i],df['dyad_end_day'][i])\n",
    "        ends.append(dce)\n",
    "    df['datecode_st']=starts\n",
    "    df['datecode_end']=ends\n",
    "    #now that we have datecodes, drop the year,month,day labels\n",
    "    df.drop(axis=1,labels=['dyad_end_year','dyad_end_month','dyad_end_day','dyad_st_year','dyad_st_month','dyad_st_day'], inplace=True)\n",
    "    #we now have cleanish data\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc26a7d-5730-477c-8c3c-3f5a69c37b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['defense','defense and ententes', 'defense, ententes and nuetrality']\n",
    "conditions=[['defense'],['defense','entente'],['defense','entente','neutrality']]\n",
    "pred_raw_acc_list=[]\n",
    "x=[0,1,2]\n",
    "start_time=665325.0\n",
    "end_time=679067.75\n",
    "\n",
    "for i in range(0,len(labels)):\n",
    "    alliances=gen_dataset(dfpp,conditions[i])\n",
    "    G= graph_constructor(alliances,start_time)\n",
    "    pred_raw_war_times= raw_check_from_to(G,start_time=start_time,end_time=end_time,time_steps=30,pred_params=None,alliances=alliances)\n",
    "    positive_rate_r=true_pred_accuracy(pred_raw_war_times[0],real_wars,start_time=start_time,end_time=end_time,day_window=30*12)\n",
    "    pred_raw_acc_list.append(positive_rate_r)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('none')\n",
    "    plt.bar_label(plt.bar(x[i],pred_raw_acc_list[i]),label=labels[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d466ae84-52c8-4958-8525-f09667b45255",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/core/indexes/range.py:413\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 0 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time \u001b[38;5;129;01min\u001b[39;00m times_lin:\n\u001b[1;32m      7\u001b[0m     G\u001b[38;5;241m=\u001b[39m graph_constructor(df,time)\n\u001b[0;32m----> 8\u001b[0m     G,names\u001b[38;5;241m=\u001b[39m\u001b[43mappend_state_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     nx\u001b[38;5;241m.\u001b[39mdraw_kamada_kawai(G,labels\u001b[38;5;241m=\u001b[39mnames)\n\u001b[1;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[7], line 32\u001b[0m, in \u001b[0;36mappend_state_names\u001b[0;34m(graph, df)\u001b[0m\n\u001b[1;32m     30\u001b[0m labels\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[0;32m---> 32\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[43mfind_country_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     graph\u001b[38;5;241m.\u001b[39mnodes[node][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m     34\u001b[0m     labels[node]\u001b[38;5;241m=\u001b[39mname\n",
      "Cell \u001b[0;32mIn[7], line 27\u001b[0m, in \u001b[0;36mfind_country_name\u001b[0;34m(country_id, dataframe)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_country_name\u001b[39m(country_id, dataframe):\n\u001b[0;32m---> 27\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mccode1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mcountry_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_name1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m name\n",
      "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/usr/lib/python3.12/site-packages/pandas/core/indexes/range.py:415\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#animation for time codes\n",
    "start=695325.0\n",
    "stop=718067.75\n",
    "#times_step=np.arange(start=start,stop=stop,step=100)\n",
    "times_lin=np.linspace(start=start,stop=stop,num=60)\n",
    "for time in times_lin:\n",
    "    G= graph_constructor(df,time)\n",
    "    G,names=append_state_names(G,df)\n",
    "    nx.draw_kamada_kawai(G,labels=names)\n",
    "    plt.show()\n",
    "    print(time/365.25)\n",
    "    clear_output(wait=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
